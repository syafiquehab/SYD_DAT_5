{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SYD DAT 5 Homework 1 - Git and Markdown - Sebastian\n",
    "\n",
    "# See additional files in the repo for the below tasks. The 5 course project ideas can be found below.\n",
    "\n",
    "#### Setup\n",
    "* Resolve any installation issues before next class.\n",
    "* Make sure you have a github profile and created a repo\n",
    "* Clone the class repo (this one!)\n",
    "* Review this [code](../labs/Week 1/00_python_refresher.py) for a recap of some Python basics.\n",
    "\n",
    "#### Communication\n",
    "* Read [Analyzing the Analyzers](http://cdn.oreillystatic.com/oreilly/radarreport/0636920029014/Analyzing_the_Analyzers.pdf) for a useful look at the different types of data scientists. Write down 5 key points you took away from the article\n",
    "* Read about some [Markdown Techniques](http://daringfireball.net/projects/markdown/syntax)\n",
    "* Write a summary of a chapter of [The Data Science Handbook](http://www.thedatasciencehandbook.com/) in Markdown and submit a pull request in the Lab Directory\n",
    "\n",
    "#### Programming\n",
    "* Complete the lab from class and the additional Exercise below\n",
    "\n",
    "#### Course Project\n",
    "* Come up with 5 different ideas for your course project. For each one list:\n",
    "  * Overview of your idea\n",
    "  * What data you will use, and how you will collect it\n",
    "  * What the outcome is that you are trying to achieve\n",
    "  * Any ideas of modelling techniques it may involve\n",
    "\n",
    "**Instructions: copy this file and append your name in the filename, e.g. Homework1_ian_hansel.ipynb.\n",
    "Then commit this in your local repository, push it to your github account and create a pull request so I can see your work. Remeber if you get stuck to look at the slides going over Fork, Clone, Commit, Push and Pull request.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Four - Movie Lens Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "users_filepath = os.path.join(os.getcwd(), \"../labs/Week 1/u.user\")\n",
    "user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users_dataframe = pd.read_table(users_filepath, sep='|', header=None, names=user_cols, index_col='user_id', dtype={'zip_code':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip_code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [age, gender, occupation, zip_code]\n",
       "Index: []"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each occupation in 'users', count the number of occurrences\n",
    "users_dataframe.occupation.value_counts()\n",
    "\n",
    "# for each occupation, calculate the mean age\n",
    "users_dataframe.groupby('occupation').age.mean()\n",
    "\n",
    "# for each occupation, calculate the minimum and maximum ages\n",
    "users_dataframe.groupby('occupation').age.min()\n",
    "users_dataframe.groupby('occupation').age.max()\n",
    "\n",
    "# for each combination of occupation and gender, calculate the mean age\n",
    "users_dataframe.groupby(['occupation', 'gender']).age.mean()\n",
    "\n",
    "# randomly sample a DataFrame\n",
    "users_dataframe.sample(10)\n",
    "\n",
    "# detect duplicate users\n",
    "# number of duplicated users:\n",
    "users_dataframe.index.duplicated().sum()\n",
    "# print the duplicated users:\n",
    "users_dataframe[users_dataframe.index.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Course Project Ideas:\n",
    "\n",
    "This is an incomplete list and I have a few other ideas. All of the ideas require some fleshing out.\n",
    "\n",
    "1. Attemping to predict the outcome of AFL games, or perhaps who will win the premiership. The website [AFL tables](http://afltables.com/afl/afl_index.html) has a good back log of data. It would be a  classification problems (ie classifying teams as winners of losers). This could just be a crazy idea and give no decent results.\n",
    "\n",
    "3. Something to do with quantitative finance and algorithmic trading. There is this platform for doing such things online called Quantopian. It allows for various bits of time series analysis. I am thinking that I am not so keen on this idea, but maybe it could be a good one.\n",
    "\n",
    "4. Build a recurrent neural network that can analyse and predict speech patterns. Data might come from corpus built into the NLTK. This seems possibly like a hard and ill defined project, but could be cool.\n",
    "\n",
    "2. Look at traffic data, attempt to analyse congestion and try to predict when a given trip will take longer than normal. Data would come from Government websites. I have briefly looked and found data about trains, planes and cycling. Not sure if there is car data.\n",
    "\n",
    "5. Build a machine learning algorithm that can learn how to play games. Eg noughts and crosses, or some other simple game. This might be hard!\n",
    "\n",
    "6. Make an auto muter for my tv, that will auto mute the ads based on the tv picture. Gotta harvest the data myself...\n",
    "\n",
    "2. Look at that school dataset you mentioned in the first class. They wanted to look at correlations between marks and which students hung out together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
